{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.layers import Flatten, Embedding\n",
    "from keras.layers import MaxPooling1D, Conv1D, GlobalMaxPool1D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from nltk.corpus import stopwords\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data\n",
    "## Data contains customer review (short sentences) and ratings (1,2,3,4 or 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:/Users/DHRUVIL/OneDrive/Stratsntools/Python Directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Womens Clothing E-Commerce Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review Text']=df['Review Text'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "## converting words like 'wouldn't' to 'would not'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "\n",
    "replacement_patterns = [\n",
    "(r'won\\'t', 'will not'),\n",
    "(r'can\\'t', 'cannot'),\n",
    "(r'i\\'m', 'i am'),\n",
    "(r'ain\\'t', 'is not'),\n",
    "(r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "(r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "(r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "(r'(\\w+)\\'s', '\\g<1> is'),\n",
    "(r'(\\w+)\\'re', '\\g<1> are'),\n",
    "(r'(\\w+)\\'d', '\\g<1> would')\n",
    "]\n",
    "\n",
    "class RegexpReplacer(object):\n",
    "    def __init__(self,patterns=replacement_patterns):\n",
    "        self.patterns=[(re.compile(regex),repl) for (regex,repl) in patterns]\n",
    "    def replace(self,text):\n",
    "        s=text\n",
    "        for (pattern,repl) in self.patterns:\n",
    "            (s,count)=re.subn(pattern,repl,s)\n",
    "        return s\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "import re\n",
    "replacer= RegexpReplacer()\n",
    "df['Review Text'] = df['Review Text'].apply(lambda x: replacer.replace(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing, Stopwords removal, Lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "df['tokenizedx'] = df['Review Text'].apply(lambda x: word_tokenize(str(x)))\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english')\n",
    "df['tokenizedx']=df['tokenizedx'].apply(lambda x: [y for y in x if y not in stop])\n",
    "\n",
    "\n",
    "df['tokenizedx'] = df['tokenizedx'].apply(lambda x: [y.lower() for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation removal and word segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "x=re.compile('[%s]' % re.escape(string.punctuation))\n",
    "def remove_punct(tokens):\n",
    "    new=[]\n",
    "    for t in tokens:\n",
    "        mt=x.sub(u'',t)\n",
    "        if not mt==u'':\n",
    "            new.append(mt)\n",
    "    return new\n",
    "\n",
    "\n",
    "from itertools import chain\n",
    "df['tokenizedx'] = df['tokenizedx'].apply(lambda x: [remove_punct(x)])\n",
    "df['tokenizedx'] = df['tokenizedx'].apply(lambda x: list(chain.from_iterable(x)))\n",
    "\n",
    "from wordsegment import load, segment\n",
    "load()\n",
    "df['tokenizedx'] = df['tokenizedx'].apply(lambda x: [segment(y) for y in x])\n",
    "from itertools import chain\n",
    "df['tokenizedx'] = df['tokenizedx'].apply(lambda x: list(chain.from_iterable(x)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Ratings label.\n",
    "## As we see a clear imbalance, we binarize the output as 0 (Ratings<=3) and 1 (Ratings>=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count=Counter(df.Rating)\n",
    "count\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_bar_x():\n",
    "    # this is for plotting purpose\n",
    "    index = range(1,6)\n",
    "    plt.bar(index, list(count.values()))\n",
    "    plt.xlabel('Genre', fontsize=5)\n",
    "    plt.ylabel('No of Movies', fontsize=5)\n",
    "    plt.xticks(index, index, fontsize=5, rotation=30)\n",
    "    plt.title('Ratings Distribution')\n",
    "    plt.show()\n",
    "\n",
    "plot_bar_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index.values.tolist():\n",
    "    if df.loc[i,'Rating']<=3:\n",
    "        df.loc[i,'Rating']='0'\n",
    "    else:\n",
    "        df.loc[i,'Rating']='1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting text to vectors\n",
    "## We define MAX_NB_WORDS as the maximum number of words we want to keep. The words are selected on the basis of their occurences in the dataset\n",
    "## Max sequence length is the maximum number of tokens we want to see in each review\n",
    "## Embedding dimension is the dimension of the word vectors we want to build\n",
    "## We use the tokenizer to tokenize the sentences (Reviews) and then convert the tokens to a sequence of numbers. The numbers denote the identity assigned to each word (tokens)\n",
    "## To ensure uniform length of the sequences, we pad them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 200000\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer=Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(df['Review Text'])\n",
    "seq=tokenizer.texts_to_sequences(df['Review Text'])\n",
    "seq=pad_sequences(seq,maxlen=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(df['Rating'])\n",
    "y=np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.4\n",
    "indices = np.arange(df.shape[0]) # get sequence of row index\n",
    "np.random.shuffle(indices) # shuffle the row indexes\n",
    "data = seq[indices] # shuffle data/product-titles/x-axis\n",
    "category = y[indices] # shuffle labels/category/y-axis\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = category[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = category[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "sentences = []\n",
    "for i in df.index.tolist():\n",
    "    sentences.append(df.loc[i,'tokenizedx'])\n",
    "\n",
    "model=gensim.models.Word2Vec(sentences,min_count=2,size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Embeddings\n",
    "## We create a numpy zeros array of dimension (words,embedding dimensions) and store vectors from Word2Vec model in rows corresponding to word indices\n",
    "## Word2Vec embeddings are used to initialize the weights of the embedding layer in the subsequent code\n",
    "## +1 in nb_words because we don't have 0 in word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHRUVIL\\Anaconda_3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))+1\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in model.wv.vocab.keys():\n",
    "        embedding_matrix[i] = model[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Layer (Does not exactly captures semantics like Word2Vec. Majorly serves the classification purpose)\n",
    "https://stats.stackexchange.com/questions/324992/how-the-embedding-layer-is-trained-in-keras-embedding-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(embedding_matrix.shape[0], # or len(word_index) + 1\n",
    "                            embedding_matrix.shape[1], # or EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "## This isn't tuned. Like mentioned, this is just a framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CNN_model = Sequential()\n",
    "CNN_model.add(embedding_layer)\n",
    "CNN_model.add(Dropout(0.5))\n",
    "CNN_model.add(Conv1D(150, 4, padding='valid',activation='relu',strides=2))\n",
    "CNN_model.add(Conv1D(250, 3, padding='valid',activation='relu',strides=2))\n",
    "CNN_model.add(Conv1D(400, 2, padding='valid',activation='relu',strides=2))\n",
    "CNN_model.add(Flatten())\n",
    "CNN_model.add(Dropout(0.5))\n",
    "CNN_model.add(Dense(150,activation='sigmoid'))\n",
    "CNN_model.add(Dense(150,activation='sigmoid'))\n",
    "CNN_model.add(Dense(150,activation='sigmoid'))\n",
    "CNN_model.add(Dense(150,activation='sigmoid'))\n",
    "CNN_model.add(Dropout(0.2))\n",
    "CNN_model.add(Dense(2,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "14092/14092 [==============================] - 14s 967us/step - loss: 0.4381 - acc: 0.7812\n",
      "Epoch 2/15\n",
      "14092/14092 [==============================] - 15s 1ms/step - loss: 0.4329 - acc: 0.7904\n",
      "Epoch 3/15\n",
      "14092/14092 [==============================] - 14s 997us/step - loss: 0.4330 - acc: 0.7903\n",
      "Epoch 4/15\n",
      "14092/14092 [==============================] - 14s 1ms/step - loss: 0.4229 - acc: 0.7978\n",
      "Epoch 5/15\n",
      "14092/14092 [==============================] - 15s 1ms/step - loss: 0.4245 - acc: 0.7943\n",
      "Epoch 6/15\n",
      "14092/14092 [==============================] - 14s 974us/step - loss: 0.4113 - acc: 0.8065\n",
      "Epoch 7/15\n",
      "14092/14092 [==============================] - 14s 965us/step - loss: 0.4105 - acc: 0.8059\n",
      "Epoch 8/15\n",
      "14092/14092 [==============================] - 14s 976us/step - loss: 0.4036 - acc: 0.8133\n",
      "Epoch 9/15\n",
      "14092/14092 [==============================] - 14s 972us/step - loss: 0.3982 - acc: 0.8117\n",
      "Epoch 10/15\n",
      "14092/14092 [==============================] - 13s 923us/step - loss: 0.3921 - acc: 0.8194\n",
      "Epoch 11/15\n",
      "14092/14092 [==============================] - 13s 932us/step - loss: 0.3909 - acc: 0.8159\n",
      "Epoch 12/15\n",
      "14092/14092 [==============================] - 14s 977us/step - loss: 0.3823 - acc: 0.8242\n",
      "Epoch 13/15\n",
      "14092/14092 [==============================] - 14s 960us/step - loss: 0.3778 - acc: 0.8259\n",
      "Epoch 14/15\n",
      "14092/14092 [==============================] - 13s 942us/step - loss: 0.3689 - acc: 0.8302\n",
      "Epoch 15/15\n",
      "14092/14092 [==============================] - 14s 958us/step - loss: 0.3625 - acc: 0.8352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ca6baf3a90>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model.fit(x_train, y_train, epochs=15, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9394/9394 [==============================] - 4s 398us/step\n"
     ]
    }
   ],
   "source": [
    "pred=CNN_model.evaluate(x_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
